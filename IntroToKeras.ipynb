{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroToKeras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "rzIFhaKO5g0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "5f8d4172-e8cb-4049-b37f-b0bd05906cf9"
      },
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Loads data and creates 2 tuples\n",
        "# (x, y): training data\n",
        "# (xt, yt): test data\n",
        "(x, y), (xt, yt) = mnist.load_data()\n",
        "\n",
        "from keras.layers import Reshape, Conv2D, Dropout, MaxPooling2D\n",
        "\n",
        "model = Sequential([\n",
        "    \n",
        "    # Creating a channel for data\n",
        "    Reshape((28, 28, 1), input_shape=(28, 28)),\n",
        "    \n",
        "    # Send into convolutional layers (great for image detection and learning filters than match small patterns within an image, stacking patterns up until later layers learn more complex combinations)\n",
        "    # Choosing number of filters in first layer with 64 channels of information\n",
        "    # Dropout: adds randomness - 20% of weights of previous layers randomly at every step - and helps model generalize itself \n",
        "    # By randomly excluding bits of data, prevents 'conspiracies' from forming\n",
        "    Conv2D(64, (3,3)), Dropout(.2), MaxPooling2D(),\n",
        "    \n",
        "    # Create a new output layer\n",
        "    Conv2D(64, (3,3)), Dropout(.2), MaxPooling2D(),\n",
        "    \n",
        "    Conv2D(64, (3,3)), Dropout(.2), MaxPooling2D(),\n",
        "\n",
        "    # Small enough at this point to flatten data, ignore spatial information and treat as one long stream of information\n",
        "    Flatten(),\n",
        "    \n",
        "    Dense(64, activation='relu'),      \n",
        "    Dense(10, activation='softmax'),      \n",
        "])\n",
        "\n",
        "# adam = very high optimizer in many situations\n",
        "model.compile(optimizer=`adam`, loss=`categorical_crossentropy`, metrics=[`acc`])\n",
        "\n",
        "# Gradient descent: \"first-order iterative optimization algorithm for finding the MINIMUM POINT of a function\"\n",
        "# Fitting Model: Given training data, look at some, make a prediction of it, and \n",
        "model.fit(x, y, epochs=10, batch_size=128, validation_data=(xt, yt), shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "11501568/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4fd8cf4c5e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Small enough at this point to flatten data, ignore spatial information and treat as one long stream of information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Flatten' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xo8fZ9kGBhia",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sequential API\n",
        "Functional API\n",
        "\n",
        "\n",
        "\n",
        "*   As training increases, training error will decrease. However, there's a point at which validation error decrease>increasing. Therefore, you can use a callback function and stop your layers/epochs early before it increases.\n",
        "\n",
        "K-Fold Cross Validation\n",
        "*   Common across neural nets and ML\n",
        "* sciKit great tool\n",
        "* Create scikit learn Keras Classifier specifying how you want it to train\n",
        "* Sklearn model selection cross validation\n",
        "\n",
        "**Book Recommendation:** Deep Learning with Python\n",
        "\n",
        "Object Detection\n",
        "Brief Overview of 2018\n",
        "\n",
        "Classification: Identifying category/class\n",
        "* Using CNN\n",
        "\n",
        "Detection: Detect multiple objects in picture, along with lcoations\n",
        "* All involve ConvNets\n",
        "* Many are based on \"repurposed\" ConvNet for image classification\n",
        "* Why not a classifier for detection? Using Bruteforce window-sliding method is too slow and no bounding box info\n",
        "\n",
        "Object Detection - Two Families\n",
        "* Two Stage Algorithm: R-CNN family\n",
        "* One Stage Algorithm: YOLO, ssd family\n",
        "\n",
        "R-CNN\n",
        "* Better approach than sliding window\n",
        "* Extract just 2000 regions\n",
        "* Use selective search (traditional computer vision approach, summarizing characteristic of regions)\n",
        "* Run each region with CNN\n",
        "* Inefficient - what if 2 regions overlap? Two CNN = inefficient\n",
        "\n",
        "Fast R-CNN\n",
        "* Instead of selective search, run through deep ConvNet\n",
        "* Learn features from ConvNet\n",
        "* Optimization: combine ConvNet with Rol Projection\n",
        "* More efficient bc only run ConvNet once\n",
        "* Significantly faster 25x of R-CNN\n",
        "* Problems: selective search is still expensive and slow\n",
        "\n",
        "Faster R-CNN\n",
        "* Eliminates selective search algorithm and lets network learn the region proposals\n",
        "* Replaced with region propsal network so the entire image becomes neural network\n",
        "* 250x faster than R-CNN\n",
        "\n",
        "YOLO\n",
        "* \"You only look once\"\n",
        "* Architecture: convnet after convnet\n",
        "* Divide picture into grids\n",
        "* Get partial info about region and bounding box, then run through ConvNet\n",
        "* Pros: Orders of magnitudes faster\n",
        "* Cons: Algorithm tends to miss smaller things\n",
        "\n",
        "Things to Consider\n",
        "* IOU (Intersection over Union)\n",
        "* Precision (mAP)\n",
        "* How fast? (fps)\n",
        "* Mobile support\n",
        "* ConvNet architecture\n",
        "* Code availability and readiness\n",
        "\n",
        "Others & Recent Advances\n",
        "* SSD: Single shot multibo  detector\n",
        "* HypterNet, FPN Network\n",
        "* Pose: Deformable CNN\n",
        "* Capsule Networks in the future?\n",
        "\n",
        "CNN; doesn't have a concept of pose (tilts, rotations, etc)\n",
        "* This is criticism of ConvNet"
      ]
    }
  ]
}